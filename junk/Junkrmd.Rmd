---
title: "All the chunk removed from the main Rmd"
author: "Riccardo Ruta"
date: '2022-05-11'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Extra dictionary

### I also added one extra dictionary including all the populist words

```{r, warning=FALSE}
# Daily Dictionary analysis with my_dictionary on the whole dataset
dfm_dict5  <- dfm_lookup(DFM_trimmed, dictionary = my_dictionary)
# Group by date
dfm_by_date5<- dfm_group(dfm_dict5, groups= date)
#kable(head(dfm_by_date5,10))
# Group by week
dfm_by_week5 <- dfm_group(dfm_dict5, groups= week)
#kable(head(dfm_by_week5,10))
# Group by month
dfm_by_month5 <- dfm_group(dfm_dict5, groups= month)
#kable(head(dfm_by_month5))
```

## General level of populism in time

```{r, echo=FALSE}
dat_smooth <- ksmooth(x = dfm_by_date5$date, 
                      y = dfm_by_date5[,"populism"] - !dfm_by_date5[,"populism"],
                      kernel = "normal", bandwidth = 30)
plot(dat_smooth$x, dat_smooth$y, type = "l", ylab = "Populism level", xlab = "")
grid()
abline(h = 0, lty = 2)
```

## Most populist party

```{r}
# Most populist party
dict_5_tstat_party <- textstat_frequency(dfm_dict5, groups = party_id)
kable(dict_5_tstat_party %>% slice_max(frequency, n = 10))
```

## Most populist politician

```{r}
dict_5_tstat_nome <- textstat_frequency(dfm_dict5, groups = nome)

kable(dict_5_tstat_nome %>% slice_max(frequency, n = 10))
```

# 13 / 05 
```{r}
```{r 30.2, echo=FALSE}
terms <- get_terms(lda_22, 10)
dt1 <- terms[,1:6]
dt2 <- terms[,7:12]
dt3 <- terms[,13:18]
dt4 <- terms[,19:22]


knitr::kable(dt1, col.names = c("Top terms 01","Top terms 02","Top terms 03",
                         "Top terms 04","Top terms 05","Top terms 06"))%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))

knitr::kable(dt2, col.names = c("Top terms 7","Top terms 8","Top terms 9",
                                "Top terms 10","Top terms 11","Top terms 12"))%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))

knitr::kable(dt3, col.names = c("Top terms 13","Top terms 14","Top terms 15",
                         "Top terms 16","Top terms 17","Top terms 18"))%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))

knitr::kable(dt4, col.names = c("Top terms 19","Top terms 20","Top terms 21",
                         "Top terms 22"))%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))

```

```{r}
titles_22 <- c("1", "2", "3", "4", "5","6",
                 "7", "8", "9", "10", "11","12",
                 "13", "14", "15", "16","17","18",
                 "19", "20", "21", "22")

table_titles_22 <- rbind (titles_22, terms)


t22.1 <- table_titles_22[,1:6]
t22.2 <- table_titles_22[,7:12]
t22.3 <- table_titles_22[,13:18]
t22.4 <- table_titles_22[,19:22]

kable(t22.1)%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
kable(t22.2)%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
kable(t22.3)%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
kable(t22.4)%>%
  kable_styling(latex_options = c("HOLD_position","scale_down"))
```



## Trim the data

Only words that occur in the top 20% of the distribution and in less than 30% of documents. Very frequent but document specific words.

```{r}
DFM_trimmed <- dfm_trim(DFM, min_termfreq = 0.80, termfreq_type = "quantile",
                        max_docfreq = 0.3, docfreq_type = "prop")

# Check the topfeatures
topfeatures(DFM_trimmed,15)
```

Take the proportion of the frequencies

```{r}
# Weight the frequency
dfm_weight <- DFM %>%
  dfm_weight(scheme = "prop")
#save(dfm_weight,file="data/dfm_weight.Rda
```

** weighted **
```{r}
# WEIGHTED
tag_fcm <- fcm(tag_dfm)
set.seed(123)
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag)
textplot_network(topgat_fcm)#, min_freq = 0.1, edge_alpha = 0.8, edge_size = 5)
```

```{r}
{r, eval=FALSE, include=FALSE}
# Check most frequent hashtag extracted with regular expressions
ht <- str_extract_all(dataset$tweet_testo, '#[A-Za-z0-9_]+')
ht <- unlist(ht)
head(sort(table(ht), decreasing = TRUE))
```

Weighted
```{r}
{r, echo=FALSE}
# WEIGHTED
user_fcm <- fcm(user_dfm)
set.seed(123)
user_fcm <- fcm_select(user_fcm, pattern = topuser)
textplot_network(user_fcm, min_freq = 0.1, edge_color = "orange", edge_alpha = 0.8, edge_size = 5)
```



```{r, echo=FALSE}
# FOCUS ON THE DICTIONARIES THAT SCORE SIMILARLY
comparison_time <- plot(dat_smooth3$x, dat_smooth3$y, type = "l", ylab = "Populism level", xlab = "Time", col = "blue",ylim = c(0.5,2))+
  lines(dat_smooth2$x, dat_smooth2$y, type = "l", ylab = "Populism level", xlab = "Time", col = "red") +
  lines(dat_smooth1$x, dat_smooth1$y, type = "l", ylab = "Populism level", xlab = "Time", col = "black")
legend("topleft", legend = c("Roodujin_pauwels","Grundl_italian", "Decadri_Boussalis_Grundl"), fill = c("red", "blue", "Black"))
title(main = "Compare how the different dictionaries score")
```


