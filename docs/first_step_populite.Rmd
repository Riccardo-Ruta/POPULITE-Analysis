---
title: "Populite - first steps"
author: "Riccardo Ruta"
date: "1/3/2022"
output: html_document
output_dir: '//docs'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Step 1 - Define the corpus

The unit of the analysis are the tweet

The corpus is the the aggregation of those tweets

a collection of corpus is defined as a CORPORA

words = tokens

tokenization = split the text into tokens

types = unique occurring word

### Step 2 - Preprocessing

### Step 3 - create the DFM (or DTM)

Bag of words approach

Each document can be represented as a vector that counts the number of times each of the "types" occur in that document

Multiple document vectors putted together define the DFM

-   each raw = is one document

-   each column = is a type (unique word or term)

-   the matrix contain the frequency of the words

### Step 4 - one more preparation step

trim = reduce the sparsity of the dfm (the presence of a lot of freq = 0)

keeping only features that appear just in 10%
